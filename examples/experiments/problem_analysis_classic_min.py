import copy
from typing import Tuple
if __name__ == "__main__": import __config__

import numpy as np
from dimensions import ChainDimension
from dimensions import Elevation
from dimensions import DayProgress
from dimensions import OCI, VCI, ACI
from dimensions import OCIModel
from dimensions import SolarDayProgress
from dimensions import Quantization
from dimensions import MeanBySolarDay
from dimensions import Declination
from dimensions import MathTransform
from dimensions import RollingAverage
from dimensions import Vectorize

from itertools import product

import pandas as pd
import os

from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from matplotlib import pyplot as plt
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score,mean_absolute_percentage_error, max_error

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense,Activation,Flatten,LSTM
from tensorflow.keras import Input

# from tensorflow.keras.wrappers.scikit_learn import KerasClassifier
# from tensorflow.keras.utils import np_utils


from SlidingWindowExperiment import SlidingWindowExperimentBase
from SlidingWindowExperiment import SlidingWindowExperimentTrajectoryBase

class SWE(SlidingWindowExperimentBase):
    def __init__(self, **kwargs):
        super(SWE, self).__init__(**kwargs)
        latitude_degrees = kwargs.get("latitude_degrees")
        longitude_degrees = kwargs.get("longitude_degrees")
        #self.chain is dimension generator. Each class (object) in transformer array creates at least one additional
        # column in returned array. Column is named by "dimension_name" and may be referenced by name in SWE call.
        # to create new Dimension class simple extend BaseDimension in dimensions directory.
        self.chain = ChainDimension(transformers=[
            # y is always here!
            DayProgress(dimension_name="Day%"),
            Declination(dimension_name="Declination"),
            Elevation(
                dimension_name="Elevation",
                latitude_degrees=latitude_degrees,
                longitude_degrees=longitude_degrees),
            # Vectorize(lagged=10, step_per_lag=10, base_dimensions=["y"]),
            SolarDayProgress(
                scale=0.01,
                latitude_degrees=latitude_degrees,
                longitude_degrees=longitude_degrees),
            VCI(
                window_size=12,
                dimension_name="VCI"),
            OCIModel(
                dimension_name="OCIModel",
                latitude_degrees=latitude_degrees,
                longitude_degrees=longitude_degrees),
            OCI(
                window_size=12,
                dimension_name="OCI",
                base_dimensions=["OCIModel"],
                latitude_degrees=latitude_degrees,
                longitude_degrees=longitude_degrees),
            ACI(window_size=12,
                dimension_name="ACI",
                base_dimensions=["OCI", "VCI"],
                latitude_degrees=latitude_degrees,
                longitude_degrees=longitude_degrees),
            MeanBySolarDay(dimension_name="ACId", base_dimensions=["ACI"],
                latitude_degrees=latitude_degrees,
                longitude_degrees=longitude_degrees),
            Quantization(k=8, dimension_name=f"qACId(8)", base_dimensions=["ACId"]),
            Quantization(k=6, dimension_name=f"qACId(6)", base_dimensions=["ACId"]),
            Quantization(k=4, dimension_name=f"qACId(4)", base_dimensions=["ACId"]),
            # MeanBySolarDay(dimension_name="OCId", base_dimensions=["OCI"],
            #     latitude_degrees=latitude_degrees,
            #     longitude_degrees=longitude_degrees),
            # Quantization(k=k, dimension_name=f"qOCId({k})", base_dimensions=["OCId"])
        ])

    # method to be overwritten -
    def fit_generate_dimensions_and_make_dataset(self,train_ts:pd.DataFrame, fh:int, predict_window_length:int) -> Tuple[pd.Series, pd.DataFrame]:
        train_ts_ex = self.chain.fit_transform(train_ts)
        #[fh:] and [:-fh] is needed to avoid look ahead. However, it is needed only in fit_(...)_dataset beacuse this
        # function gets train_ts and transforms it into features and labels. predict_(...)_dataset gets predict_ts(X) and
        # test_df (Y) separately. SWE ensres that those two sets do not overlap in time domain
        train_ds_y = train_ts_ex.iloc[fh:]["y"] # y contains ground truth
        train_ds_x = train_ts_ex.iloc[:-fh] # it contains features generated by chain transform and y observations
        return train_ds_y, train_ds_x

    # method to be overwritten
    def predict_generate_dimensions_and_make_dataset(self, predict_ts:pd.DataFrame, test_ts:pd.DataFrame, fh:int) -> Tuple[pd.Series, pd.DataFrame]:
        #print("predict_ts.shape", predict_ts.shape, "self.predict_window_length_", self.predict_window_length_)
        test_ts_ex = self.chain.transform(predict_ts)

        test_ds_y = test_ts # test_df is a series containing ground truth
        test_ds_x = test_ts_ex # it contains features generated by chain transform and y observations

        return test_ds_y, test_ds_x

def test(model, model_name="model", k=4, n = 10, n_steps = 28,instance=0, excluded_dims=None):
    file_path = "/".join(os.path.abspath(__file__).split("/")[:-2] + ["../datasets/dataset.csv"])
    dataset = pd.read_csv(file_path, low_memory=False)
    # self.full_data = self.full_data[30:]
    dataset['timestamp'] = pd.to_datetime(dataset['timestamp'])
    dataset.index = dataset['timestamp']
    dataset.drop(columns=["timestamp"], inplace=True)
    dataset = dataset[:2*360*288].loc["2020-04-18":]

    print(dataset.columns)

    #prepare test
    latitude_degrees = dataset[f"{instance}_Latitude"][0]
    longitude_degrees = dataset[f"{instance}_Longitude"][0]

    df = pd.DataFrame({}, index=dataset.index)
    df["power"] = dataset[f"{instance}_Power"]
    df.fillna(0, inplace=True)
    swe = SWE(k=k, latitude_degrees=latitude_degrees, longitude_degrees=longitude_degrees)
    swe.register_dataset(df)

    # sample model. register_model takes several arguments that configures test. Remember to set "model name" since it
    # appears in metrics as index. If you leave dimensions name not provided model will use all dimensions available in
    # chain. You can easly configure fit or predict wrapping model in class that has predict and fit methods
    # swe.register_model(MLPRegressor(hidden_layer_sizes=(20, 20, 20), max_iter=500, random_state=0), "MLP", ["SolarDay%", "qACId"])
    excluded_dims = excluded_dims if excluded_dims is not None else []
    dims = [d for d in swe.all_dims if not d in excluded_dims + ["OCIModel", "OCI", "VCI", "ACI", "ACId", "qACId(8)", "qACId(6)", "qACId(4)"]] # remove dims needed for calculations
    # swe.register_model(model,model_name, dims=dims, n=n, n_step=n_steps) # reference case
    swe.register_model(copy.deepcopy(model),model_name, dims=dims) # test case
    # swe.register_model(create_lstm_keras_model(hidded_layers=(20, 10), input_shape=(20, len(dims)), output_shape=1),"tf::LSTM(20,10)", dims, n=20, n_step=28)

    # select metrics for model evaluations
    swe.register_metric(mean_absolute_error, "MAE")
    swe.register_metric(mean_squared_error, "MSE")
    # swe.register_metric(mean_absolute_percentage_error, "MAPE")
    # swe.register_metric(max_error, "ME")

    # run test and store results in metrics_df.
    _,metrics_df,_ = swe()
    # store metrics in file format
    metrics_df.to_csv(f"cm/concat_.csv")

    # display interactive charts (use keyboards arrows)
    # plotter = swe.show_results()
    # plotter2 = swe.show_fit_dimensions()
    # plt.show()

    return metrics_df

if __name__ == "__main__":
    n = 10
    n_steps = 10
    dimensions = 6 # y, Elevation, Day%, SolarDay%, Declination, qACId

    instances = [0,1,2]
    models = [
        (KNeighborsRegressor(10), "KNN(10)"),
        (make_pipeline(PolynomialFeatures(12), LinearRegression()), "LR(12)"),
        (RandomForestRegressor(), "RF")
    ]

    all_metrics = pd.DataFrame({})
    for instance in instances:
        for m in models:
            metrics_df = test(
                excluded_dims = ["y", "Day%", "Elevation", "Declination"], # solar day  + qacid
                model = m[0],
                model_name=m[1],
                # n = n,
                # n_steps = n_steps,
                instance=instance # dataset contains data from 3 different pv power plants
            )
            metrics_df["instance"] = instance
            all_metrics = pd.concat([all_metrics, metrics_df])
            print(all_metrics)

    print(all_metrics)